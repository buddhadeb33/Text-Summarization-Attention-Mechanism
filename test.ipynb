{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Summarization || Deep Learning || NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/buddha/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/buddha/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/buddha/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#import all the required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from statistics import mode\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import LancasterStemmer\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import Input,LSTM,Embedding,Dense,Concatenate,Attention\n",
    "from sklearn.model_selection import train_test_split\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the dataset file for text Summarizer\n",
    "df=pd.read_csv(\"data/Reviews.csv\",nrows=100000)\n",
    "#drop the duplicate and na values from the records\n",
    "df.drop_duplicates(subset=['Text'],inplace=True)\n",
    "df.dropna(axis=0,inplace=True)\n",
    "input_data = df.loc[:,'Text']\n",
    "target_data = df.loc[:,'Summary']\n",
    "target_data.replace('', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_texts=[]\n",
    "target_texts=[]\n",
    "input_words=[]\n",
    "target_words=[]\n",
    "contractions=pickle.load(open(\"contractions.pkl\",\"rb\"))['contractions']\n",
    "#initialize stop words and LancasterStemmer\n",
    "stop_words=set(stopwords.words('english'))\n",
    "stemm=LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(texts,src):\n",
    "  #remove the html tags\n",
    "  texts = BeautifulSoup(texts, \"lxml\").text\n",
    "  #tokenize the text into words \n",
    "  words=word_tokenize(texts.lower())\n",
    "  #filter words which contains \\ \n",
    "  #integers or their length is less than or equal to 3\n",
    "  words= list(filter(lambda w:(w.isalpha() and len(w)>=3),words))\n",
    "  #contraction file to expand shortened words\n",
    "  words= [contractions[w] if w in contractions else w for w in words ]\n",
    "  #stem the words to their root word and filter stop words\n",
    "  if src==\"inputs\":\n",
    "    words= [stemm.stem(w) for w in words if w not in stop_words]\n",
    "  else:\n",
    "    words= [w for w in words if w not in stop_words]\n",
    "  return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pass the input records and taret records\n",
    "for in_txt,tr_txt in zip(input_data,target_data):\n",
    "  in_words= clean(in_txt,\"inputs\")\n",
    "  input_texts+= [' '.join(in_words)]\n",
    "  input_words+= in_words\n",
    "  #add 'sos' at start and 'eos' at end of text\n",
    "  tr_words= clean(\"sos \"+tr_txt+\" eos\",\"target\")\n",
    "  target_texts+= [' '.join(tr_words)]\n",
    "  target_words+= tr_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of input words :  32198\n",
      "number of target words :  14171\n",
      "maximum input length :  74\n",
      "maximum target length :  17\n"
     ]
    }
   ],
   "source": [
    "#store only unique words from input and target list of words\n",
    "input_words = sorted(list(set(input_words)))\n",
    "target_words = sorted(list(set(target_words)))\n",
    "num_in_words = len(input_words) #total number of input words\n",
    "num_tr_words = len(target_words) #total number of target words\n",
    " \n",
    "#get the length of the input and target texts which appears most often  \n",
    "max_in_len = mode([len(i) for i in input_texts])\n",
    "max_tr_len = mode([len(i) for i in target_texts])\n",
    " \n",
    "print(\"number of input words : \",num_in_words)\n",
    "print(\"number of target words : \",num_tr_words)\n",
    "print(\"maximum input length : \",max_in_len)\n",
    "print(\"maximum target length : \",max_tr_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the input and target text into 80:20 ratio or testing size of 20%.\n",
    "x_train,x_test,y_train,y_test=train_test_split(input_texts,target_texts,test_size=0.2,random_state=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the tokenizer with all the words\n",
    "in_tokenizer = Tokenizer()\n",
    "in_tokenizer.fit_on_texts(x_train)\n",
    "tr_tokenizer = Tokenizer()\n",
    "tr_tokenizer.fit_on_texts(y_train)\n",
    " \n",
    "#convert text into sequence of integers\n",
    "#where the integer will be the index of that word\n",
    "x_train= in_tokenizer.texts_to_sequences(x_train) \n",
    "y_train= tr_tokenizer.texts_to_sequences(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pad array of 0's if the length is less than the maximum length \n",
    "en_in_data= pad_sequences(x_train,  maxlen=max_in_len, padding='post') \n",
    "dec_data= pad_sequences(y_train,  maxlen=max_tr_len, padding='post')\n",
    " \n",
    "#decoder input data will not include the last word \n",
    "#i.e. 'eos' in decoder input data\n",
    "dec_in_data = dec_data[:,:-1]\n",
    "#decoder target data will be one time step ahead as it will not include\n",
    "# the first word i.e 'sos'\n",
    "dec_tr_data = dec_data.reshape(len(dec_data),max_tr_len,1)[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 8.00 GB\n",
      "maxCacheSize: 2.67 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-20 21:20:36.585684: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-20 21:20:36.592648: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2021-12-20 21:20:36.593660: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "K.clear_session() \n",
    "latent_dim = 500\n",
    " \n",
    "#create input object of total number of encoder words\n",
    "en_inputs = Input(shape=(max_in_len,)) \n",
    "en_embedding = Embedding(num_in_words+1, latent_dim)(en_inputs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create 3 stacked LSTM layer with the shape of hidden dimension for text summarizer using deep learning\n",
    "#LSTM 1\n",
    "en_lstm1= LSTM(latent_dim, return_state=True, return_sequences=True) \n",
    "en_outputs1, state_h1, state_c1= en_lstm1(en_embedding) \n",
    " \n",
    "#LSTM2\n",
    "en_lstm2= LSTM(latent_dim, return_state=True, return_sequences=True) \n",
    "en_outputs2, state_h2, state_c2= en_lstm2(en_outputs1) \n",
    " \n",
    "#LSTM3\n",
    "en_lstm3= LSTM(latent_dim,return_sequences=True,return_state=True)\n",
    "en_outputs3 , state_h3 , state_c3= en_lstm3(en_outputs2)\n",
    " \n",
    "#encoder states\n",
    "en_states= [state_h3, state_c3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create 3 stacked LSTM layer with the shape of hidden dimension for text summarizer using deep learning\n",
    "#LSTM 1\n",
    "en_lstm1= LSTM(latent_dim, return_state=True, return_sequences=True) \n",
    "en_outputs1, state_h1, state_c1= en_lstm1(en_embedding) \n",
    " \n",
    "#LSTM2\n",
    "en_lstm2= LSTM(latent_dim, return_state=True, return_sequences=True) \n",
    "en_outputs2, state_h2, state_c2= en_lstm2(en_outputs1) \n",
    " \n",
    "#LSTM3\n",
    "en_lstm3= LSTM(latent_dim,return_sequences=True,return_state=True)\n",
    "en_outputs3 , state_h3 , state_c3= en_lstm3(en_outputs2)\n",
    " \n",
    "#encoder states\n",
    "en_states= [state_h3, state_c3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder. \n",
    "dec_inputs = Input(shape=(None,)) \n",
    "dec_emb_layer = Embedding(num_tr_words+1, latent_dim) \n",
    "dec_embedding = dec_emb_layer(dec_inputs) \n",
    " \n",
    "#initialize decoder's LSTM layer with the output states of encoder\n",
    "dec_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "dec_outputs, *_ = dec_lstm(dec_embedding,initial_state=en_states) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Attention layer\n",
    "attention =Attention()\n",
    "attn_out = attention([dec_outputs,en_outputs3])\n",
    " \n",
    "#Concatenate the attention output with the decoder outputs\n",
    "merge=Concatenate(axis=-1, name='concat_layer1')([dec_outputs,attn_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dense layer (output layer)\n",
    "dec_dense = Dense(num_tr_words+1, activation='softmax') \n",
    "dec_outputs = dec_dense(merge) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 74)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 74, 500)      16099500    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, 74, 500), (N 2002000     embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   [(None, 74, 500), (N 2002000     lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 500)    7086000     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_5 (LSTM)                   [(None, 74, 500), (N 2002000     lstm_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_6 (LSTM)                   [(None, None, 500),  2002000     embedding_1[0][0]                \n",
      "                                                                 lstm_5[0][1]                     \n",
      "                                                                 lstm_5[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "attention_1 (Attention)         (None, None, 500)    0           lstm_6[0][0]                     \n",
      "                                                                 lstm_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer1 (Concatenate)     (None, None, 1000)   0           lstm_6[0][0]                     \n",
      "                                                                 attention_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 14172)  14186172    concat_layer1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 45,379,672\n",
      "Trainable params: 45,379,672\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "#Model class and model summary for text Summarizer\n",
    "model = Model([en_inputs, dec_inputs], dec_outputs) \n",
    "model.summary()\n",
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Cannot assign a device for operation model_2/embedding/embedding_lookup: Could not satisfy explicit device specification '/job:localhost/replica:0/task:0/device:GPU:0' because no supported kernel for GPU devices is available.\nColocation Debug Info:\nColocation group had the following types and supported devices: \nRoot Member(assigned_device_name_index_=2 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\nRealDiv: GPU CPU \nSqrt: GPU CPU \nGatherV2: GPU CPU \nAssignVariableOp: GPU CPU \nUnsortedSegmentSum: GPU CPU \nIdentity: GPU CPU \nStridedSlice: CPU \nConst: GPU CPU \nNoOp: GPU CPU \nMul: GPU CPU \nShape: GPU CPU \n_Arg: GPU CPU \nResourceScatterAdd: GPU CPU \nUnique: CPU \nReadVariableOp: GPU CPU \nAddV2: GPU CPU \nResourceGather: GPU CPU \n\nColocation members, user-requested devices, and framework assigned devices, if any:\n  model_2_embedding_embedding_lookup_17013 (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0\n  rmsprop_rmsprop_update_readvariableop_resource (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0\n  model_2/embedding/embedding_lookup (ResourceGather) /job:localhost/replica:0/task:0/device:GPU:0\n  model_2/embedding/embedding_lookup/Identity (Identity) /job:localhost/replica:0/task:0/device:GPU:0\n  RMSprop/RMSprop/update/Unique (Unique) /job:localhost/replica:0/task:0/device:GPU:0\n  RMSprop/RMSprop/update/Shape (Shape) /job:localhost/replica:0/task:0/device:GPU:0\n  RMSprop/RMSprop/update/strided_slice/stack (Const) /job:localhost/replica:0/task:0/device:GPU:0\n  RMSprop/RMSprop/update/strided_slice/stack_1 (Const) /job:localhost/replica:0/task:0/device:GPU:0\n  RMSprop/RMSprop/update/strided_slice/stack_2 (Const) /job:localhost/replica:0/task:0/device:GPU:0\n  RMSprop/RMSprop/update/strided_slice (StridedSlice) /job:localhost/replica:0/task:0/device:GPU:0\n  RMSprop/RMSprop/update/UnsortedSegmentSum (UnsortedSegmentSum) /job:localhost/replica:0/task:0/device:GPU:0\n  RMSprop/RMSprop/update/mul (Mul) /job:localhost/replica:0/task:0/device:GPU:0\n  RMSprop/RMSprop/update/mul_1 (Mul) /job:localhost/replica:0/task:0/device:GPU:0\n  RMSprop/RMSprop/update/ReadVariableOp (ReadVariableOp) \n  RMSprop/RMSprop/update/mul_2 (Mul) /job:localhost/replica:0/task:0/device:GPU:0\n  RMSprop/RMSprop/update/AssignVariableOp (AssignVariableOp) /job:localhost/replica:0/task:0/device:GPU:0\n  RMSprop/RMSprop/update/ResourceScatterAdd (ResourceScatterAdd) /job:localhost/replica:0/task:0/device:GPU:0\n  RMSprop/RMSprop/update/ReadVariableOp_1 (ReadVariableOp) \n  RMSprop/RMSprop/update/GatherV2/axis (Const) /job:localhost/replica:0/task:0/device:GPU:0\n  RMSprop/RMSprop/update/GatherV2 (GatherV2) /job:localhost/replica:0/task:0/device:GPU:0\n  RMSprop/RMSprop/update/mul_3 (Mul) /job:localhost/replica:0/task:0/device:GPU:0\n  RMSprop/RMSprop/update/Sqrt (Sqrt) /job:localhost/replica:0/task:0/device:GPU:0\n  RMSprop/RMSprop/update/add (AddV2) /job:localhost/replica:0/task:0/device:GPU:0\n  RMSprop/RMSprop/update/truediv (RealDiv) /job:localhost/replica:0/task:0/device:GPU:0\n  RMSprop/RMSprop/update/ResourceScatterAdd_1 (ResourceScatterAdd) /job:localhost/replica:0/task:0/device:GPU:0\n  RMSprop/RMSprop/update/ReadVariableOp_2 (ReadVariableOp) \n  RMSprop/RMSprop/update/group_deps (NoOp) /job:localhost/replica:0/task:0/device:GPU:0\n\nOp: ResourceGather\nNode attrs: _class=[\"loc:@model_2/embedding/embedding_lookup/17013\"], batch_dims=0, Tindices=DT_INT32, dtype=DT_FLOAT, validate_indices=true\nRegistered kernels:\n  device='XLA_CPU_JIT'; Tindices in [DT_INT32, DT_INT64]; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_BFLOAT16, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]\n  device='GPU'; dtype in [DT_INT64]; Tindices in [DT_INT32]\n  device='GPU'; dtype in [DT_INT64]; Tindices in [DT_INT64]\n  device='GPU'; dtype in [DT_FLOAT]; Tindices in [DT_INT32]\n  device='GPU'; dtype in [DT_FLOAT]; Tindices in [DT_INT64]\n  device='CPU'; dtype in [DT_UINT64]; Tindices in [DT_INT32]\n  device='CPU'; dtype in [DT_UINT64]; Tindices in [DT_INT64]\n  device='CPU'; dtype in [DT_INT64]; Tindices in [DT_INT32]\n  device='CPU'; dtype in [DT_INT64]; Tindices in [DT_INT64]\n  device='CPU'; dtype in [DT_UINT32]; Tindices in [DT_INT32]\n  device='CPU'; dtype in [DT_UINT32]; Tindices in [DT_INT64]\n  device='CPU'; dtype in [DT_UINT16]; Tindices in [DT_INT32]\n  device='CPU'; dtype in [DT_UINT16]; Tindices in [DT_INT64]\n  device='CPU'; dtype in [DT_INT16]; Tindices in [DT_INT32]\n  device='CPU'; dtype in [DT_INT16]; Tindices in [DT_INT64]\n  device='CPU'; dtype in [DT_UINT8]; Tindices in [DT_INT32]\n  device='CPU'; dtype in [DT_UINT8]; Tindices in [DT_INT64]\n  device='CPU'; dtype in [DT_INT8]; Tindices in [DT_INT32]\n  device='CPU'; dtype in [DT_INT8]; Tindices in [DT_INT64]\n  device='CPU'; dtype in [DT_INT32]; Tindices in [DT_INT32]\n  device='CPU'; dtype in [DT_INT32]; Tindices in [DT_INT64]\n  device='CPU'; dtype in [DT_HALF]; Tindices in [DT_INT32]\n  device='CPU'; dtype in [DT_HALF]; Tindices in [DT_INT64]\n  device='CPU'; dtype in [DT_BFLOAT16]; Tindices in [DT_INT32]\n  device='CPU'; dtype in [DT_BFLOAT16]; Tindices in [DT_INT64]\n  device='CPU'; dtype in [DT_FLOAT]; Tindices in [DT_INT32]\n  device='CPU'; dtype in [DT_FLOAT]; Tindices in [DT_INT64]\n  device='CPU'; dtype in [DT_DOUBLE]; Tindices in [DT_INT32]\n  device='CPU'; dtype in [DT_DOUBLE]; Tindices in [DT_INT64]\n  device='CPU'; dtype in [DT_COMPLEX64]; Tindices in [DT_INT32]\n  device='CPU'; dtype in [DT_COMPLEX64]; Tindices in [DT_INT64]\n  device='CPU'; dtype in [DT_COMPLEX128]; Tindices in [DT_INT32]\n  device='CPU'; dtype in [DT_COMPLEX128]; Tindices in [DT_INT64]\n  device='CPU'; dtype in [DT_BOOL]; Tindices in [DT_INT32]\n  device='CPU'; dtype in [DT_BOOL]; Tindices in [DT_INT64]\n  device='CPU'; dtype in [DT_STRING]; Tindices in [DT_INT32]\n  device='CPU'; dtype in [DT_STRING]; Tindices in [DT_INT64]\n  device='CPU'; dtype in [DT_RESOURCE]; Tindices in [DT_INT32]\n  device='CPU'; dtype in [DT_RESOURCE]; Tindices in [DT_INT64]\n  device='CPU'; dtype in [DT_VARIANT]; Tindices in [DT_INT32]\n  device='CPU'; dtype in [DT_VARIANT]; Tindices in [DT_INT64]\n  device='CPU'; dtype in [DT_QINT8]; Tindices in [DT_INT32]\n  device='CPU'; dtype in [DT_QINT8]; Tindices in [DT_INT64]\n  device='CPU'; dtype in [DT_QUINT8]; Tindices in [DT_INT32]\n  device='CPU'; dtype in [DT_QUINT8]; Tindices in [DT_INT64]\n  device='CPU'; dtype in [DT_QINT32]; Tindices in [DT_INT32]\n  device='CPU'; dtype in [DT_QINT32]; Tindices in [DT_INT64]\n\n\t [[{{node model_2/embedding/embedding_lookup}}]] [Op:__inference_train_function_21402]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/yh/hfxvgm8d1kdg3tf0f75kf3tr0000gn/T/ipykernel_95888/1102624495.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m model.compile( \n\u001b[1;32m      2\u001b[0m     optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"] ) \n\u001b[0;32m----> 3\u001b[0;31m model.fit( \n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0men_in_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_in_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdec_tr_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    948\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3037\u001b[0m       (graph_function,\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3039\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1963\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Cannot assign a device for operation model_2/embedding/embedding_lookup: Could not satisfy explicit device specification '/job:localhost/replica:0/task:0/device:GPU:0' because no supported kernel for GPU devices is available.\nColocation Debug Info:\nColocation group had the following types and supported devices: \nRoot Member(assigned_device_name_index_=2 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\nRealDiv: GPU CPU \nSqrt: GPU CPU \nGatherV2: GPU CPU \nAssignVariableOp: GPU CPU \nUnsortedSegmentSum: GPU CPU \nIdentity: GPU CPU \nStridedSlice: CPU \nConst: GPU CPU \nNoOp: GPU CPU \nMul: GPU CPU \nShape: GPU CPU \n_Arg: GPU CPU \nResourceScatterAdd: GPU CPU \nUnique: CPU \nReadVariableOp: GPU CPU \nAddV2: GPU CPU \nResourceGather: GPU CPU \n\nColocation members, user-requested devices, and framework assigned devices, if any:\n  model_2_embedding_embedding_lookup_17013 (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0\n  rmsprop_rmsprop_update_readvariableop_resource (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0\n  model_2/embedding/embedding_lookup (ResourceGather) /job:localhost/replica:0/task:0/device:GPU:0\n  model_2/embedding/embedding_lookup/Identity (Identity) /job:localhost/replica:0/task:0/device:GPU:0\n  RMSprop/RMSprop/update/Unique (Unique) /job:localhost/replica:0/task:0/device:GPU:0\n  RMSprop/RMSprop/update/Shape (Shape) /job:localhost/replica:0/task:0/device:GPU:0\n  RMSprop/RMSprop/update/strided_slice/stack (Const) /job:localhost/replica:0/task:0/device:GPU:0\n  RMSprop/RMSprop/update/strided_slice/stack_1 (Const) /job:localhost/replica:0/task:0/device:GPU:0\n  RMSprop/RMSprop/update/strided_slice/stack_2 (Const) /job:localhost/replica:0/task:0/device:GPU:0\n  RMSprop/RMSprop/update/strided_slice (StridedSlice) /job:localhost/replica:0/task:0/device:GPU:0\n  RMSprop/RMSprop/update/UnsortedSegmentSum (UnsortedSegmentSum) /job:localhost/replica:0/task:0/device:GPU:0\n  RMSprop/RMSprop/update/mul (Mul) /job:localhost/replica:0/task:0/device:GPU:0\n  RMSprop/RMSprop/update/mul_1 (Mul) /job:localhost/replica:0/task:0/device:GPU:0\n  RMSprop/RMSprop/update/ReadVariableOp (ReadVariableOp) \n  RMSprop/RMSprop/update/mul_2 (Mul) /job:localhost/replica:0/task:0/device:GPU:0\n  RMSprop/RMSprop/update/AssignVariableOp (AssignVariableOp) /job:localhost/replica:0/task:0/device:GPU:0\n  RMSprop/RMSprop/update/ResourceScatterAdd (ResourceScatterAdd) /job:localhost/replica:0/task:0/device:GPU:0\n  RMSprop/RMSprop/update/ReadVariableOp_1 (ReadVariableOp) \n  RMSprop/RMSprop/update/GatherV2/axis (Const) /job:localhost/replica:0/task:0/device:GPU:0\n  RMSprop/RMSprop/update/GatherV2 (GatherV2) /job:localhost/replica:0/task:0/device:GPU:0\n  RMSprop/RMSprop/update/mul_3 (Mul) /job:localhost/replica:0/task:0/device:GPU:0\n  RMSprop/RMSprop/update/Sqrt (Sqrt) /job:localhost/replica:0/task:0/device:GPU:0\n  RMSprop/RMSprop/update/add (AddV2) /job:localhost/replica:0/task:0/device:GPU:0\n  RMSprop/RMSprop/update/truediv (RealDiv) /job:localhost/replica:0/task:0/device:GPU:0\n  RMSprop/RMSprop/update/ResourceScatterAdd_1 (ResourceScatterAdd) /job:localhost/replica:0/task:0/device:GPU:0\n  RMSprop/RMSprop/update/ReadVariableOp_2 (ReadVariableOp) \n  RMSprop/RMSprop/update/group_deps (NoOp) /job:localhost/replica:0/task:0/device:GPU:0\n\nOp: ResourceGather\nNode attrs: _class=[\"loc:@model_2/embedding/embedding_lookup/17013\"], batch_dims=0, Tindices=DT_INT32, dtype=DT_FLOAT, validate_indices=true\nRegistered kernels:\n  device='XLA_CPU_JIT'; Tindices in [DT_INT32, DT_INT64]; dtype in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_BFLOAT16, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]\n  device='GPU'; dtype in [DT_INT64]; Tindices in [DT_INT32]\n  device='GPU'; dtype in [DT_INT64]; Tindices in [DT_INT64]\n  device='GPU'; dtype in [DT_FLOAT]; Tindices in [DT_INT32]\n  device='GPU'; dtype in [DT_FLOAT]; Tindices in [DT_INT64]\n  device='CPU'; dtype in [DT_UINT64]; Tindices in [DT_INT32]\n  device='CPU'; dtype in [DT_UINT64]; Tindices in [DT_INT64]\n  device='CPU'; dtype in [DT_INT64]; Tindices in [DT_INT32]\n  device='CPU'; dtype in [DT_INT64]; Tindices in [DT_INT64]\n  device='CPU'; dtype in [DT_UINT32]; Tindices in [DT_INT32]\n  device='CPU'; dtype in [DT_UINT32]; Tindices in [DT_INT64]\n  device='CPU'; dtype in [DT_UINT16]; Tindices in [DT_INT32]\n  device='CPU'; dtype in [DT_UINT16]; Tindices in [DT_INT64]\n  device='CPU'; dtype in [DT_INT16]; Tindices in [DT_INT32]\n  device='CPU'; dtype in [DT_INT16]; Tindices in [DT_INT64]\n  device='CPU'; dtype in [DT_UINT8]; Tindices in [DT_INT32]\n  device='CPU'; dtype in [DT_UINT8]; Tindices in [DT_INT64]\n  device='CPU'; dtype in [DT_INT8]; Tindices in [DT_INT32]\n  device='CPU'; dtype in [DT_INT8]; Tindices in [DT_INT64]\n  device='CPU'; dtype in [DT_INT32]; Tindices in [DT_INT32]\n  device='CPU'; dtype in [DT_INT32]; Tindices in [DT_INT64]\n  device='CPU'; dtype in [DT_HALF]; Tindices in [DT_INT32]\n  device='CPU'; dtype in [DT_HALF]; Tindices in [DT_INT64]\n  device='CPU'; dtype in [DT_BFLOAT16]; Tindices in [DT_INT32]\n  device='CPU'; dtype in [DT_BFLOAT16]; Tindices in [DT_INT64]\n  device='CPU'; dtype in [DT_FLOAT]; Tindices in [DT_INT32]\n  device='CPU'; dtype in [DT_FLOAT]; Tindices in [DT_INT64]\n  device='CPU'; dtype in [DT_DOUBLE]; Tindices in [DT_INT32]\n  device='CPU'; dtype in [DT_DOUBLE]; Tindices in [DT_INT64]\n  device='CPU'; dtype in [DT_COMPLEX64]; Tindices in [DT_INT32]\n  device='CPU'; dtype in [DT_COMPLEX64]; Tindices in [DT_INT64]\n  device='CPU'; dtype in [DT_COMPLEX128]; Tindices in [DT_INT32]\n  device='CPU'; dtype in [DT_COMPLEX128]; Tindices in [DT_INT64]\n  device='CPU'; dtype in [DT_BOOL]; Tindices in [DT_INT32]\n  device='CPU'; dtype in [DT_BOOL]; Tindices in [DT_INT64]\n  device='CPU'; dtype in [DT_STRING]; Tindices in [DT_INT32]\n  device='CPU'; dtype in [DT_STRING]; Tindices in [DT_INT64]\n  device='CPU'; dtype in [DT_RESOURCE]; Tindices in [DT_INT32]\n  device='CPU'; dtype in [DT_RESOURCE]; Tindices in [DT_INT64]\n  device='CPU'; dtype in [DT_VARIANT]; Tindices in [DT_INT32]\n  device='CPU'; dtype in [DT_VARIANT]; Tindices in [DT_INT64]\n  device='CPU'; dtype in [DT_QINT8]; Tindices in [DT_INT32]\n  device='CPU'; dtype in [DT_QINT8]; Tindices in [DT_INT64]\n  device='CPU'; dtype in [DT_QUINT8]; Tindices in [DT_INT32]\n  device='CPU'; dtype in [DT_QUINT8]; Tindices in [DT_INT64]\n  device='CPU'; dtype in [DT_QINT32]; Tindices in [DT_INT32]\n  device='CPU'; dtype in [DT_QINT32]; Tindices in [DT_INT64]\n\n\t [[{{node model_2/embedding/embedding_lookup}}]] [Op:__inference_train_function_21402]"
     ]
    }
   ],
   "source": [
    "model.compile( \n",
    "    optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"] ) \n",
    "model.fit( \n",
    "    [en_in_data, dec_in_data],\n",
    "    dec_tr_data, \n",
    "    batch_size=512, \n",
    "    epochs=10, \n",
    "    validation_split=0.1,\n",
    "    )\n",
    " \n",
    "#Save model\n",
    "model.save(\"s2s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31b5c3825b4c7bd3d755fd286f100198491b64be37977664ffdcf26a174ce3da"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('mlp': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
